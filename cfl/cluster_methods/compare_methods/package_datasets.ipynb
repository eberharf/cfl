{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0b9f90a7866deec4ec91106178f5b99f4479e17c39f9cdadf9218e367e68d50a4",
   "display_name": "Python 3.7.9 64-bit ('cfl_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import compare\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from visual_bars.generate_visual_bars_data import VisualBarsData\n",
    "from cfl.util.data_processing import one_hot_encode\n",
    "from cfl.experiment import Experiment\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "base_path = '/Users/imanwahle/Desktop/cfl/cfl/cluster_methods/compare_methods'\n",
    "TAG = ''\n",
    "DATA_PATH = os.path.join(base_path, 'data_' + TAG)\n",
    "RESULTS_PATH = os.path.join(base_path, 'results_' + TAG)\n",
    "FIG_PATH = os.path.join(base_path, 'figures_' + TAG)\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)\n",
    "if not os.path.exists(FIG_PATH):\n",
    "    os.makedirs(FIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "n_samples = 5000\n",
    "random_state = 42\n",
    "data_names = ['blobs_const', 'blobs_vard', 'mnist', 'vb_noise0.0', 'vb_noise0.1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # CDE params for vis_bars datasets\n",
    "# CNN_params = { # parameters for model creation\n",
    "#                     'filters'         : [32, 16],\n",
    "#                     'input_shape'     : (10, 10, 1),\n",
    "#                     'kernel_size'     : [(3, 3)] *2,\n",
    "#                     'pool_size'       : [(2, 2)] *2,\n",
    "#                     'padding'         : ['same'] *2,\n",
    "#                     'conv_activation' : ['softmax', 'softmax'],\n",
    "#                     'dense_units'     : 16,\n",
    "#                     'dense_activation' : 'softmax',\n",
    "#                     'output_activation': 'softmax',\n",
    "\n",
    "#                     # parameters for training\n",
    "#                     'batch_size'  : 32,\n",
    "#                     'n_epochs'    : 40,\n",
    "#                     'optimizer'   : 'adam',\n",
    "#                     'opt_config'  : {},\n",
    "#                     'verbose'     : 2,\n",
    "#                     'weights_path': None,\n",
    "#                     'loss'        : 'mean_squared_error',\n",
    "#                     'show_plot'   : True,\n",
    "#                     'standardize' : False,\n",
    "#                     'best'        : True,\n",
    "#                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def save_data(dataset, data_name):\n",
    "    os.mkdir(os.path.join(DATA_PATH, data_name))\n",
    "    np.save(os.path.join(DATA_PATH, data_name, 'data_to_cluster.npy'), dataset[0])\n",
    "    np.save(os.path.join(DATA_PATH, data_name, 'true_labels.npy'), dataset[1])\n",
    "\n",
    "def visualize_data(dataset, data_name):\n",
    "    # get embedding\n",
    "    if dataset[0].shape[1] > 2:\n",
    "        embedding = compare.get_embedding(DATA_PATH, data_name)\n",
    "    else:\n",
    "        embedding = dataset[0]\n",
    "\n",
    "    # make subplot\n",
    "    fig,ax = plt.subplots()\n",
    "    if (embedding.shape[1]==1) or (np.sum(embedding)==embedding.shape[0]):\n",
    "        compare._hist_helper(ax, embedding, dataset[1], data_name, subscript=None)\n",
    "    else:\n",
    "        compare._scatter_helper(ax, embedding, dataset[1], data_name, subscript=None)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_vb_data(n_samples, noise_lvl, random_state):\n",
    "    vb_data = VisualBarsData(n_samples=n_samples, noise_lvl=noise_lvl, set_random_seed=random_state)\n",
    "    X = vb_data.getImages()\n",
    "    pyx_gt = vb_data.getGroundTruth()\n",
    "    Y = vb_data.getTarget()\n",
    "    return X, pyx_gt, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following blocks are written as stand-alone processes to generate each dataset. \n",
    "# Only run the ones you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uniform variance blobs\n",
    "\n",
    "# data = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "# save_data(data, data_names[0])\n",
    "# visualize_data(data, data_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # varied variance blobs\n",
    "\n",
    "# data = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5],  random_state=random_state)\n",
    "# save_data(data, data_names[1])\n",
    "# visualize_data(data, data_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mnist digits\n",
    "\n",
    "# (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "# train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1]*train_X.shape[2]))\n",
    "\n",
    "# # we only want n_samples points from mnist for now\n",
    "# np.random.seed(random_state)\n",
    "# idx = np.random.choice(range(train_X.shape[0]), n_samples, replace=False)\n",
    "# data = [train_X[idx,:], train_y[idx,]]\n",
    "\n",
    "# save_data(data, data_names[2])\n",
    "# visualize_data(data, data_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # causal mnist setup\n",
    "# from cfl import util\n",
    "# import random\n",
    "\n",
    "# # Generate target (Y) data. Here 'a' and 'b' are represent alpha and beta\n",
    "# targets = ['a', 'b']\n",
    "\n",
    "# distributions = [[0.95, 0.05], [0.05, 0.95], [0.5, 0.5]]\n",
    "\n",
    "# def get_distribution(val):\n",
    "#     if val <= 3:\n",
    "#         return distributions[0]\n",
    "#     elif val <= 6:\n",
    "#         return distributions[1]\n",
    "#     else:\n",
    "#         return distributions[2]\n",
    "\n",
    "# def generate_target(data):\n",
    "#     target = []\n",
    "#     for val in data:\n",
    "#         target += (random.choices(targets, get_distribution(val)))\n",
    "#     return np.array(target)\n",
    "\n",
    "# # generate true Xmacro labels\n",
    "# def get_Xmacro(Xmicro_label):\n",
    "#     Xmacro = np.zeros(Xmicro_label.shape)\n",
    "#     for xmli,xml in enumerate(Xmicro_label):\n",
    "#         if xml <= 3:\n",
    "#             Xmacro[xmli] = 0\n",
    "#         elif xml <= 6:\n",
    "#             Xmacro[xmli] = 1\n",
    "#         else:\n",
    "#             Xmacro[xmli] = 2\n",
    "#     return Xmacro\n",
    "\n",
    "#     # CDE parameters\n",
    "# CNN_params = { # parameters for model creation\n",
    "#                 'filters'         : [32, 16],\n",
    "#                 'input_shape'     : (28, 28, 1),\n",
    "#                 'kernel_size'     : [(3, 3)] *2,\n",
    "#                 'pool_size'       : [(2, 2)] *2,\n",
    "#                 'padding'         : ['same'] *2,\n",
    "#                 'conv_activation' : ['softmax', 'softmax'],\n",
    "#                 'dense_units'     : 500,\n",
    "#                 'dense_activation' : 'softmax',\n",
    "#                 'output_activation': 'softmax',\n",
    "    \n",
    "#                 # parameters for training\n",
    "#                     'batch_size'  : 128,\n",
    "#                     'n_epochs'    : 30,\n",
    "#                     'optimizer'   : 'adam',\n",
    "#                     'opt_config'  : {},\n",
    "#                     'verbose'     : 2,\n",
    "#                     'weights_path': None,\n",
    "#                     'loss'        : 'categorical_crossentropy',\n",
    "#                     'show_plot'   : True,\n",
    "#                     'standardize' : False,\n",
    "#                     'best'        : True,\n",
    "#               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # causal mnist\n",
    "\n",
    "# # load data\n",
    "# (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# # Keep only data 1-9\n",
    "# train_X = train_X[train_y != 0]\n",
    "# train_y = train_y[train_y != 0]\n",
    "\n",
    "# del test_X, test_y\n",
    "\n",
    "# # We must divide convert the image values from [0, 255] to [0, 1] to speed up training\n",
    "# MAX_RGB = 255\n",
    "# train_X = np.true_divide(train_X, MAX_RGB)\n",
    "# train_X = np.expand_dims(train_X, -1)\n",
    "# macro_X = get_Xmacro(train_y)\n",
    "# target_Y = util.data_processing.one_hot_encode(generate_target(train_y), targets)\n",
    "# print(train_X.shape)\n",
    "# print(train_y.shape)\n",
    "# print(macro_X.shape)\n",
    "# print(target_Y.shape)\n",
    "\n",
    "# data_info = { 'X_dims' : train_X.shape, \n",
    "#               'Y_dims' : target_Y.shape, \n",
    "#               'Y_type' : 'categorical' } \n",
    "                         \n",
    "# block_names = ['CondExpCNN']\n",
    "# block_params = [CNN_params]\n",
    "\n",
    "# save_path = '/Users/imanwahle/Desktop/cfl/cfl/cluster_methods/compare_methods/tmp_cfl_results'\n",
    "# my_exp = Experiment(X_train=train_X, Y_train=target_Y, data_info=data_info, \n",
    "#                     block_names=block_names, block_params=block_params, \n",
    "#                     blocks=None, results_path=save_path)\n",
    "\n",
    "# results = my_exp.train()\n",
    "# pyx = results['CondExpCNN']['pyx']\n",
    "\n",
    "# # package data\n",
    "# # we only want n_samples points from mnist for now\n",
    "# np.random.seed(random_state)\n",
    "# idx = np.random.choice(range(train_X.shape[0]), n_samples, replace=False)\n",
    "# data = [pyx[idx,], macro_X[idx,]]\n",
    "# save_data(data, 'causal_mnist')\n",
    "# visualize_data(data, 'causal_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visual bars CDE output\n",
    "# X, pyx_gt, Y = get_vb_data(n_samples, 0.0, random_state)\n",
    "\n",
    "# # format data for CDE training\n",
    "# X = np.expand_dims(X, -1)\n",
    "# Y = one_hot_encode(Y, unique_labels=[0,1])\n",
    "\n",
    "# data_info = {'X_dims': X.shape,\n",
    "#              'Y_dims': Y.shape,\n",
    "#              'Y_type': 'categorical'}\n",
    "\n",
    "# block_names = ['CondExpCNN']\n",
    "# block_params = [CNN_params]\n",
    "\n",
    "# save_path = '/Users/imanwahle/Desktop/cfl/cfl/cluster_methods/compare_methods/tmp_cfl_results'\n",
    "# my_exp = Experiment(X_train=X, Y_train=Y, data_info=data_info, \n",
    "#                     block_names=block_names, block_params=block_params, \n",
    "#                     blocks=None, results_path=save_path)\n",
    "\n",
    "# results = my_exp.train()\n",
    "# pyx = results['CondExpCNN']['pyx']\n",
    "\n",
    "# # package data\n",
    "# data = [pyx, pyx_gt]\n",
    "# save_data(data, data_names[3])\n",
    "# visualize_data(data, data_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visual bars CDE output\n",
    "# X, pyx_gt, Y = get_vb_data(n_samples, 0.1, random_state)\n",
    "\n",
    "# # format data for CDE training\n",
    "# X = np.expand_dims(X, -1)\n",
    "# Y = one_hot_encode(Y, unique_labels=[0,1])\n",
    "\n",
    "# data_info = {'X_dims': X.shape,\n",
    "#              'Y_dims': Y.shape,\n",
    "#              'Y_type': 'categorical'}\n",
    "\n",
    "# block_names = ['CondExpCNN']\n",
    "# block_params = [CNN_params]\n",
    "\n",
    "# save_path = '/Users/imanwahle/Desktop/cfl/cfl/cluster_methods/compare_methods/tmp_cfl_results'\n",
    "# my_exp = Experiment(X_train=X, Y_train=Y, data_info=data_info, \n",
    "#                     block_names=block_names, block_params=block_params, \n",
    "#                     blocks=None, results_path=save_path)\n",
    "\n",
    "# results = my_exp.train()\n",
    "# pyx = results['CondExpCNN']['pyx']\n",
    "\n",
    "# # package data\n",
    "# data = [pyx, pyx_gt]\n",
    "# save_data(data, data_names[4])\n",
    "# visualize_data(data, data_names[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uniform variance blobs\n",
    "# for n_features in np.arange(1000,7000,1000):\n",
    "#     data = datasets.make_blobs(n_samples=n_samples, n_features=n_features, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
    "#     save_data(data, f'blobs_const_{n_features}')\n",
    "#     visualize_data(data, f'blobs_const_{n_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mnist with varied resolution\n",
    "# from skimage.transform import resize\n",
    "\n",
    "# res = np.arange(10,120,20)\n",
    "# for r,ri in tqdm(enumerate(res)):\n",
    "\n",
    "#     (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "#     del train_X, train_y\n",
    "\n",
    "#     # we only want n_samples points from mnist for now\n",
    "#     np.random.seed(random_state)\n",
    "#     idx = np.random.choice(range(test_X.shape[0]), 10, replace=False)\n",
    "#     test_X = test_X[idx,:]\n",
    "#     test_y = test_y[idx,]\n",
    "\n",
    "#     # vary image resolution and vectorize\n",
    "#     test_X = np.array([resize(test_X[i], (r,r)) for i in range(test_X.shape[0])])\n",
    "#     test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1]*test_X.shape[2]))\n",
    "\n",
    "#     # package it all up\n",
    "#     data = [test_X, test_y]\n",
    "\n",
    "#     save_data(data, f'mnist_{r}')\n",
    "#     visualize_data(data, f'mnist_{r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/imanwahle/Desktop/cfl/cfl/cluster_methods/compare_methods/data_/el_nino_pyx/embedding.npy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-76743bd313ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpyx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyx_gt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'el_nino_pyx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mvisualize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'el_nino_pyx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-d60140460db9>\u001b[0m in \u001b[0;36mvisualize_data\u001b[0;34m(dataset, data_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# get embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cfl/cfl/cluster_methods/compare_methods/compare.py\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(data_path, dataset_name)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mdata_to_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_to_cluster.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/cfl_env/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/imanwahle/Desktop/cfl/cfl/cluster_methods/compare_methods/data_/el_nino_pyx/embedding.npy'"
     ]
    }
   ],
   "source": [
    "# el nino  cde output\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "cfl_path = '/Users/imanwahle/Desktop/cfl' # set this to your own cfl location\n",
    "X, Y, coords = joblib.load(os.path.join(cfl_path, 'data/el_nino/elnino_data.pkl'))\n",
    "imshape = (55, 9)\n",
    "\n",
    "# standardize data\n",
    "X = StandardScaler().fit_transform(X)\n",
    "Y = StandardScaler().fit_transform(Y)\n",
    "\n",
    "# set all CFL parameters\n",
    "\n",
    "# generic data parameters\n",
    "data_info = { 'X_dims' : X.shape, \n",
    "              'Y_dims' : Y.shape,\n",
    "              'Y_type' : 'continuous' } \n",
    "\n",
    "# CDE parameters\n",
    "lr = 1e-4\n",
    "CDE_params = { 'batch_size'  : 64,\n",
    "               'optimizer'   : 'adam',\n",
    "               'n_epochs'    : 40,\n",
    "               'verbose'     : True,\n",
    "               'dense_units' : [1024, 1024, data_info['Y_dims'][1]],\n",
    "               'activations' : ['linear', 'linear', 'linear'],\n",
    "               'dropouts'    : [0.1, 0.1, 0.0],\n",
    "}\n",
    "\n",
    "\n",
    "block_names = ['CondExpMod']\n",
    "block_params = [CDE_params]\n",
    "\n",
    "save_path = '/Users/imanwahle/Desktop/cfl/cfl/cluster_methods/compare_methods/tmp_cfl_results'\n",
    "my_exp = Experiment(X_train=X, Y_train=Y, data_info=data_info, \n",
    "                    block_names=block_names, block_params=block_params, \n",
    "                    blocks=None, results_path=save_path)\n",
    "\n",
    "results = my_exp.train()\n",
    "pyx = results['CondExpMod']['pyx']\n",
    "\n",
    "# package data\n",
    "pyx_gt = -1 * np.ones((pyx.shape[0],))\n",
    "data = [pyx, pyx_gt]\n",
    "save_data(data, 'el_nino_pyx')\n",
    "visualize_data(data, 'el_nino_pyx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}