{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('cfl': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ea50db4133b457ed310f46829128a01e24dcdc0c51cf4b9d361731348e8b8671"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PTSD Mouse Data \n",
    "\n",
    "The total data consist of two data sets, measuring responses from 20 different mice at 4 timepoints each: Baseline, Pre-fear exposure, immediately after the Fear exposure, and 9 days later (D9). 10 of these mice are seratonin transporter knockouts (KO) and 10 are wildtype (WT). \n",
    "\n",
    "The data are: \n",
    "- 79 MRIs. The pre-fear, fear, and D9 images are MN(II) enhanced MRIs (MEMRI). The MEMRI images are used to measure neuronal functioning - (when neurons are active, their uptake of MN(II) is increased?). The baseline images, which are regular fMRI, are \n",
    "- 79 measurements of percent time spent in the light by the mice. \n",
    "\n",
    "In both data sets, the KO_04_D9 datapoint is missing (hence 79 instead of 80). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages for analysis\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import cfl_examples.lesion_mapping.brain_util as BU\n",
    "import cfl_examples.lesion_mapping.brain_vis as BV\n",
    "\n",
    "# load response data \n",
    "Y = pd.read_pickle('Y.pkl')"
   ]
  },
  {
   "source": [
    "# MRI Data \n",
    "Some facts about the data: \n",
    "- the dimensions of the brain box in each image are (124, 200, 82) (2,033,600 voxels total)\n",
    "- the images are originally in RPS orientation. We flip them to RAS orientation because then they have the same alignment as some other MRIs we've been looking at "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_csv = 'PTSD_Data_Share\\Behavior_data\\PTSD_PerLight.csv'\n",
    "mri_dir = 'PTSD_Data_Share\\MEMRI_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('R', 'P', 'S')\n(124, 200, 82)\n"
     ]
    }
   ],
   "source": [
    "# The images start out in RPS orientation\n",
    "nib_loaded_img = nib.load(os.path.join(mri_dir, \"PTSD_KO_03_BL.nii\"))\n",
    "print(nib.orientations.aff2axcodes(nib_loaded_img.affine))\n",
    "\n",
    "# load one image to check out its dimensions\n",
    "img = BU.load_brain(os.path.join(mri_dir, \"PTSD_KO_03_BL.nii\"))\n",
    "mri_dims = img.shape\n",
    "print(mri_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the images in RAS orientation \n",
    "X, Y_unused = BU.load_data(mri_dir, behav_csv, mri_dims, ori='RAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all images are the same shape \n",
    "for fp in os.listdir(mri_dir):\n",
    "    full_path = os.path.join(mri_dir, fp)\n",
    "    brain = BU.load_brain(full_path)\n",
    "    assert brain.shape ==  mri_dims\n",
    "    #print(brain.shape)"
   ]
  },
  {
   "source": [
    "# Load Masks\n",
    "We were given two masks to fit the the MRIs, a linearly aligned- and non-linearly aligned mask. These masks tell which voxels in the image are part of the brain vs which are empty space. \n",
    "\n",
    "The difference between the non-linear and linear mask (from an email from Taylor): \"The non-linearly aligned mask is better aligned to the data, however the non-linear \"warping\" creates artifacts near the surface of the brain that may result in grabbing more undesired non-brain voxels when masking. The linearly aligned mask may not align to the surface of the brain as well and may miss or cut out brain tissue, but may not grab as many non-brain voxels. \n",
    "\n",
    "The non-linear mask leaves 531,632 voxels and the linear mask 482,793 voxels unmasked. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 1.]\n[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# both masks are binary arrays, containing 1s where there is brain and 0s where there is not \n",
    "print(np.unique(nl_mask))\n",
    "print(np.unique(l_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the non-linear mask template\n",
    "nl_mask_path = os.path.join('PTSD_Data_Share/templates\\MuseTemplate_nonlinear_mask.nii')\n",
    "nl_mask = BU.load_brain(nl_mask_path)\n",
    "nolin_mask_vec = BU.flatten(nl_mask)\n",
    "\n",
    "# load the linear mask template\n",
    "l_mask_path = os.path.join('PTSD_Data_Share/templates\\MuseTemplate_linear_mask.nii')\n",
    "l_mask = BU.load_brain(l_mask_path)\n",
    "lin_mask_vec = BU.flatten(l_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\n"
     ]
    }
   ],
   "source": [
    "print(nl_mask.shape == mri_dims) #non-linear mask has same dims as other MRI images\n",
    "print(l_mask.shape == mri_dims) #linear mask has same dims as other MRI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Non-linear mask:  531632\nLinear mask:  482793\n"
     ]
    }
   ],
   "source": [
    "# how many voxels are unmasked? \n",
    "print(\"Non-linear mask: \", np.sum(nolin_mask_vec==1))\n",
    "print(\"Linear mask: \", np.sum(lin_mask_vec==1))"
   ]
  },
  {
   "source": [
    "\n",
    "When we visualize the two masks side-by-side on an MRI below, we indeed see that the non-linear mask has a bumpier edge, with more little islands of disconnected MRI image, while the linear mask has a smoother edge but cuts off some brain tissue. For now, we are using only the non-linearly aligned mask."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97c70a6d2d8248dfaa55330a42cfd9f4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f69265888b2246f7a39aade4596422b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57713e54b08445e0af0ee52025ea7bcd"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# specify labels for plot (note the labels below are specifically for RAS orientation)\n",
    "dir_labels = { 'saggital' :   ['P', 'A', 'D', 'V'],\n",
    "               'coronal' :    ['L', 'R', 'D', 'V'],\n",
    "               'horizontal' : ['L', 'R', 'A', 'P']} \n",
    "\n",
    "# create a copy of one image with each mask already applied\n",
    "nl_masked_brain = X[0].copy()\n",
    "nl_masked_brain[BU.flatten(nl_mask)==0] = np.nan\n",
    "\n",
    "l_masked_brain = X[0].copy()\n",
    "l_masked_brain[BU.flatten(l_mask)==0] = np.nan\n",
    "\n",
    "# generate interactive plots\n",
    "BV.plot_interactive_panels(np.vstack((nl_masked_brain, l_masked_brain)), mri_dims, nolin_mask_vec, figsize=(12, 3), std_scale='std', dir_labels=dir_labels, column_titles=[\"Non-linear Mask\", \"Linear Mask\"])\n"
   ]
  },
  {
   "source": [
    "# Click through a bunch of the mice \n",
    "\n",
    "The below images compare, side-by-side, MRIs from multiple mice from the same timepoint. Since the first 5 brains in the list were selected, these are all MRIs from KO mice. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71e4006671ed4f82b4e715a2f13d585b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bbcf00f28b143d58dea0efad8bd4f9e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8106859a9f644b828dc0b6eaf41102ad"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "baseline_indices = Y[Y[\"Timepoint\"]==\"BL\"].index.tolist()\n",
    "prefear_indices = Y[Y[\"Timepoint\"]==\"PreF\"].index.tolist()\n",
    "postfear_indices = Y[Y[\"Timepoint\"]==\"Fear\"].index.tolist()\n",
    "d9_indices = Y[Y[\"Timepoint\"]==\"D9\"].index.tolist() \n",
    "timepoints_dir = {'BL' : baseline_indices, 'PreF': prefear_indices, \"Fear\": postfear_indices, 'D9': d9_indices}\n",
    "\n",
    "\n",
    "# Show first 5 baseline images \n",
    "BV.plot_interactive_panels(X[baseline_indices[:5]], mri_dims, nolin_mask_vec, figsize=(15, 5), colormap=\"seismic\", dir_labels=dir_labels, column_titles=[\"Mouse 1\", \"Mouse 2\", \"Mouse 3\", \"Mouse 4\", \"Mouse 5\"])"
   ]
  },
  {
   "source": [
    "Some observations: \n",
    "Top (Saggital) Image \n",
    "- around slices 32-39, pieces of brain appear and disappear irregularly\n",
    "- slice 39-40: lot more white in second image than others (and again around 85-89)\n",
    "- 62 - dot of high activation, high for all except fourth\n",
    "\n",
    "Middle (Coronal) Image \n",
    "- 20-40: noticeable difference in brightness of images (esp bt 1st and 3rd)\n",
    "- higher brightness in 2 noticeable at 52-54\n",
    "\n",
    "Botton (Horizontal) Image \n",
    "- the lower brightness of 4th brain is again visible (note high activation regions at slices ~16-36) \n",
    "- higher brightness of 2nd brain visible around slice ~46 \n",
    "\n",
    "\n",
    "Do the white dots of high activity (ie those in observations above, also coronal slice 64) have a known meaning? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8e3c3066fcb40a0a217d4ddc48d8ec0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31b0fc34c9b94d5d9ebc8f38138acfaf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49603fbb8ca842b68b616dc50cdc7b84"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Show first 5 prefear images \n",
    "BV.plot_interactive_panels(X[prefear_indices[:5]], mri_dims, nolin_mask_vec, figsize=(15, 5), colormap=\"seismic\", dir_labels=dir_labels, step=1)"
   ]
  },
  {
   "source": [
    "3rd brain brightest, then 4th brain, least bright is 1st\n",
    "\n",
    "Top (Saggital) Image \n",
    "- 39-40: bright spots (same as in baseline images)\n",
    "\n",
    "\n",
    "Coronal \n",
    "- around slice 30-44: the circles in the brain kind of appear differently in different images - the brains may not be perfectly aligned ? \n",
    "- 54: bright spot \n",
    "- 68: bright spots \n",
    "- 80: really bright spots \n",
    "- 124: really bright spots\n",
    "\n",
    "\n",
    "Horizontal\n",
    "- lots of artifacts visible at beginning\n",
    "- 17: really bright spots (brainstem connection to brain?)\n",
    "- some interesting structures toward the end \n",
    "\n",
    "\n",
    "- which images are generally brightest/darkest vary between images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c25ca1de72c492799cee186941b7297"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f54c9f874e544eaa256f8b1fdc382dd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5f990a62d9047e6929ea3cd4c384d2f"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Show first 5 fear images \n",
    "BV.plot_interactive_panels(X[postfear_indices[:5]], mri_dims, nolin_mask_vec, figsize=(15, 5), colormap=\"seismic\", dir_labels=dir_labels, step=1)"
   ]
  },
  {
   "source": [
    "Saggital image \n",
    "- 39: bright spot\n",
    "- 54: tiny bright spot at the bottom of the brain \n",
    "- 62, 63, 64: abrupt shifts in where the bright/dark patterns are (this is present in the earlier images too but it's clearer in these)\n",
    "\n",
    "Coronal \n",
    "- 30+ : the circles that seemed somewhat misaligned in the pre-fear images are not so in this set \n",
    "- 71: really bright spots \n",
    "- 77: really bright spots \n",
    "\n",
    "\n",
    "Horistonal \n",
    "- 16 bright spots \n",
    "- 56: on 2nd and 5th brains, the bright teardrop-shaped spots look a little asymetrical (left larger than right)\n",
    "\n",
    "\n",
    "\n",
    "- All of these brains look generally consistent in brightness\n",
    "\n",
    "\n",
    "These images generally look brighter, but I think that's just because the brightest brightest activation for this set of images (>25000) is lower than for BL or Pre-F (>30000)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3d54f7a17a64965a4502014fec410cb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c768af2f3c54860929e7e95d8a740c4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b688b8dcd0df4d8bbdc2f9ca62927f41"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Show first 5 D9 images \n",
    "BV.plot_interactive_panels(X[d9_indices[:5]], mri_dims, nolin_mask_vec, figsize=(15, 5), colormap=\"seismic\", dir_labels=dir_labels, step=1)"
   ]
  },
  {
   "source": [
    "# Heatmap \n",
    "\n",
    "These heatmaps show the average value of each voxel for the group "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Heatmap with each timepoint broken out "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 100.50it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 186.90it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 215.05it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 174.18it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_indices = Y[Y[\"Timepoint\"]==\"BL\"].index.tolist()\n",
    "prefear_indices = Y[Y[\"Timepoint\"]==\"PreF\"].index.tolist()\n",
    "postfear_indices = Y[Y[\"Timepoint\"]==\"Fear\"].index.tolist()\n",
    "d9_indices = Y[Y[\"Timepoint\"]==\"D9\"].index.tolist() \n",
    "timepoints_dir = {'BL' : baseline_indices, 'PreF': prefear_indices, \"Fear\": postfear_indices, 'D9': d9_indices}\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# HM_list = [] \n",
    "# for timepoint in timepoints_dir: \n",
    "#     currentHM = np.zeros(np.prod(mri_dims))\n",
    "#     indices = timepoints_dir[timepoint]\n",
    "#     n = len(timepoints_dir[timepoint])\n",
    "#     for brain in tqdm(X[indices]):\n",
    "#         currentHM += brain\n",
    "#     np.divide(currentHM, n)\n",
    "#     HM_list.append(currentHM)\n",
    "\n",
    "#     save_name = 'heatmap_' + timepoint + '.npy'\n",
    "#     np.save(os.path.join(save_name), currentHM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54773628626f4fd78cc3a6fded482c8c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "832388c4c2e74cfcb9699dc389f54f6e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc02194246f64c0a816d34cbb437c65c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# load heatmaps \n",
    "heatmap_names = ['heatmap_' + str(timepoint) for timepoint in timepoints_dir.keys()]\n",
    "HM_list = []\n",
    "for heatmap in heatmap_names: \n",
    "    HM_list.append(np.load(heatmap + '.npy'))\n",
    "\n",
    "# display heatmaps \n",
    "BV.plot_interactive_panels(np.vstack(HM_list), mri_dims, nolin_mask_vec, figsize=(17, 3), dir_labels=dir_labels, column_titles=list(timepoints_dir))"
   ]
  },
  {
   "source": [
    "The Baseline images are in general slightly darker than the other images. \n",
    "\n",
    "My interpretation of this is that, since the baseline images are not Mn(II) enhanced, the high activity peaks are lower relative to the background level of activity, and since all the images have been normalized along the same scale, the 'low activity' or 'normal' activity levels for the Baseline images have a higher numeric value after normalization compared to  the other images. \n",
    "\n",
    "\"Overall, the greater in magnitude the voxel intensity value of a contrast enhanced image comparing to each animal's baseline non-contrast enhanced image, corresponds to greater Mn(II) accumulation i.e. neural activity in a particular cluster of voxels.\"\n",
    "\n",
    "From this statement, I think they may be saving that we should analyze the intensity in a pre-fear/fear/D9 image minus the intensity in the baseline image, in order to find spikes in activity? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Since the \"artifacts\" on the edge of the brain are generally 0 (regardless of whether they're from the baseline or not), it seems like the artifacts end up appearing as \"neutral\" - the activity is about the same between baseline and fear image \n",
    "\n",
    "- is this true or are the artifacts negative? \n",
    "\n",
    "- how does this show up with individual images (non heatmaps)?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Baseline Adjustment\n",
    "\n",
    "In this section, images with the baseline MRI subtracted off are shown. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to subtract off the baseline \n",
    "def adjust_image(X, id, timepoint): \n",
    "    '''input: X (array of MRI images), ID of mouse and timepoint to use (\"PreF\", \"Fear\", \"D9\")\n",
    "\n",
    "    returns baseline-adjusted image\n",
    "    '''\n",
    "    # get image for that mouse at that timepoint \n",
    "    image_index = Y.loc[(Y.ID==id) & (Y.Timepoint==timepoint)].index[0]\n",
    "    image = X[image_index]\n",
    "\n",
    "    # get image for that mouse at baseline \n",
    "    baseline_index = Y.loc[(Y.ID==id) & (Y.Timepoint==\"BL\")].index[0]\n",
    "    baseline_image = X[baseline_index]\n",
    "\n",
    "    # subtract baseline from timepoint image \n",
    "    adjusted_mri = image - baseline_image\n",
    "\n",
    "    return adjusted_mrir4"
   ]
  },
  {
   "source": [
    "## Baseline-adjusted Images for an individual mouse \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7a835f3ca88472e9ec99dc178659036"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd23bacd23e54ca784e46bb20bf1bde9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e8b4d4d781148a793a6bf158714f282"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# plot to show the baseline-adjusted images for an individual mouse \n",
    "mouse_id = 7\n",
    "\n",
    "# get image for that mouse at baseline \n",
    "baseline_index = Y.loc[(Y.ID==mouse_id) & (Y.Timepoint==\"BL\")].index[0]\n",
    "baseline_image = X[baseline_index]\n",
    "\n",
    "# get other origianl images for mouse\n",
    "prefear_index = Y.loc[(Y.ID==mouse_id) & (Y.Timepoint==\"PreF\")].index[0]\n",
    "postfear_index = Y.loc[(Y.ID==mouse_id) & (Y.Timepoint==\"Fear\")].index[0]\n",
    "d9_index = Y.loc[(Y.ID==mouse_id) & (Y.Timepoint==\"D9\")].index[0]\n",
    "\n",
    "#examine a single baseline adjusted image (individual images)\n",
    "all_ims = np.zeros((3, np.prod(mri_dims)))\n",
    "for i, timepoint in enumerate([\"PreF\", \"Fear\", \"D9\"]): \n",
    "    adj_im = adjust_image(X, mouse_id, timepoint)\n",
    "    adj_im = BU.flatten(adj_im)\n",
    "    all_ims[i] += adj_im\n",
    "\n",
    "BV.plot_interactive_panels(np.vstack((baseline_image,  X[prefear_index], all_ims[0],  X[postfear_index], all_ims[1])), mri_dims, nolin_mask_vec, figsize=(17, 5), dir_labels=dir_labels, column_titles=[\"Baseline\", \"Pre-fear\", \"Adj Pre-fear\", \"Fear\", \"Adj Fear\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0a6c279077741cc84398edf038c7202"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22d8502310694b65b11490271f32a1d6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ee54f04e9e34207ba5f0be8af12ea88"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "BV.plot_interactive_panels(np.vstack((baseline_image, X[d9_index], all_ims[2])), mri_dims, nolin_mask_vec, figsize=(12, 5), dir_labels=dir_labels, column_titles=[\"Baseline\", \"D9\", \"Adj D9\"])\n"
   ]
  },
  {
   "source": [
    "## Heatmap of each timepoint, adjusted by baseline intensity \n",
    "\n",
    "Heatmap = mean value for each timepoint across all MRIs "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "HM_dir = {'PreF': np.zeros(np.prod(mri_dims)), \"Fear\": np.zeros(np.prod(mri_dims)), 'D9': np.zeros(np.prod(mri_dims))}\n",
    "all_mouse_indices = pd.unique(Y[\"ID\"])\n",
    "\n",
    "\n",
    "for timepoint in HM_dir:\n",
    "    # for each mouse....\n",
    "    for mouse_id in all_mouse_indices:\n",
    "        # get the image associated with that timepoint, subtract off the baseline\n",
    "        if mouse_id != 1 or timepoint != 'D9': #don't do this for the missing value\n",
    "            adjusted_mri = adjust_image(X, mouse_id, timepoint)\n",
    "            # add the result to the correct heatmap entry \n",
    "            HM_dir[timepoint] += BU.flatten(adjusted_mri)\n",
    "    # divide to get the average \n",
    "    n = len(timepoints_dir[timepoint])\n",
    "    np.divide(HM_dir[timepoint], n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1a8a4b6c8b14ba681d502f32f2e43fa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3044d52cde3d43f0a1fc1df5e61e43ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bf5964b717e4412ae6c84f2cebbe1c4"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "BV.plot_interactive_panels(np.vstack(list(HM_dir.values())), mri_dims, nolin_mask_vec, figsize=(12, 3), dir_labels=dir_labels, column_titles=list(HM_dir.keys()))\n"
   ]
  },
  {
   "source": [
    "# Variance\n",
    "This plot shows the level of variance between individual voxels in all the MRIs for each timepoint."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=123), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85be5742cf0648d7b3c446030a53b662"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=199), Output(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea904cf405b242bf9fa17dbd0cd417d1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=81), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfa8d9feae8e43a2be94ff5f55c61215"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "var_dir = timepoints_dir.copy()\n",
    "for timepoint in timepoints_dir: \n",
    "\n",
    "    current_var = np.var(X[timepoints_dir[timepoint]], axis=0)\n",
    "    var_dir[timepoint] = current_var\n",
    "\n",
    "BV.plot_interactive_panels(np.vstack(var_dir.values()), mri_dims, nolin_mask_vec, figsize=(15, 5), dir_labels=dir_labels, colormap=\"Reds\", step= 1, column_titles=[\"Baseline Variance\", \"Pre-fear Variance\", \"Fear Variance\", \"D9 Variance\"]) "
   ]
  },
  {
   "source": [
    " The variance tends to be highest on the edges of the brain or in small regions inside of the brain. I believe these regions correspond with the regions of high activity seen above in the individual MRIs. The variance seems to be fairly constant across mice. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Coarsening\n",
    "\n",
    "In the following code, we coarsen the mouse MRIs in order to reduce their dimensionality to more manegeable sizes. The coarsening is done by collapsing n x n cubes of voxels into a single voxel, where n is referred to as the 'coarsening factor'. The new single voxel contains the average value of the previous cube of voxels. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_coarsen(x, coarsening_factor, brain_dims):\n",
    "    ''' coarsens brain by specified amount\n",
    "    arguments:\n",
    "        x: 3D array of brain or 1D array of flattened brain\n",
    "        coarsening_factor: how many original voxels to include in new voxel along a dimension\n",
    "        brain_dims: array containing [dim0, dim1, dim2] of 3D brain (int array)\n",
    "    returns:\n",
    "        new_x: 3D array of coarsened brain\n",
    "    '''\n",
    "    # make 3D if flattened\n",
    "    if x.ndim < 3:\n",
    "        x = BU.unflatten(x, brain_dims)\n",
    "\n",
    "    brain_dims = np.array(brain_dims)\n",
    "    new_dims = np.ceil(brain_dims/coarsening_factor).astype(int)\n",
    "    new_x = np.zeros(new_dims)\n",
    "    for i in range(new_dims[0]):\n",
    "        for j in range(new_dims[1]):\n",
    "            for k in range(new_dims[2]):\n",
    "                # select all voxels to contribute to coarsened voxel (i,j,k)\n",
    "                istart = i*coarsening_factor\n",
    "                jstart = j*coarsening_factor\n",
    "                kstart = k*coarsening_factor\n",
    "                iend = np.min((istart+coarsening_factor, brain_dims[0])) # handle edge case\n",
    "                jend = np.min((jstart+coarsening_factor, brain_dims[1]))\n",
    "                kend = np.min((kstart+coarsening_factor, brain_dims[2]))\n",
    "\n",
    "                sample = x[istart:iend, jstart:jend, kstart:kend]\n",
    "\n",
    "\n",
    "                # average \n",
    "                new_x[i, j, k] = np.average(sample)\n",
    "    return new_x\n"
   ]
  },
  {
   "source": [
    "## Coarsened Brain of a single mouse \n",
    "\n",
    "If we coarsen by a factor of 3, then the resultant brain goes from dimensions (124, 80, 200) and about 2,000,000 voxels in the brain box to: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New dims:  (42, 67, 28)\nNumber of voxels:  78792\n"
     ]
    }
   ],
   "source": [
    "coarsening_factor = 3\n",
    "\n",
    "##Coarsen using new coarsening function \n",
    "coarsened_brain = new_coarsen(brain, coarsening_factor, np.array(mri_dims))\n",
    "\n",
    "#coarsened non linear mask\n",
    "coarsened_nl_mask = BU.flatten(BU.coarsen(nl_mask, coarsening_factor, np.array(mri_dims)))\n",
    "\n",
    "print(\"New dims: \", coarsened_brain.shape)\n",
    "print(\"Number of voxels: \", np.prod(coarsened_brain.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=41), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c33cb4074a324a10ab3be92136c52c2d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=66), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec98f47892fa4f38aa88bec285bb55b9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=27), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36cd1469d4af4626bac2b3c858e26ba2"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "single_mouse_all_mris = np.zeros((4, np.prod(coarsened_brain.shape)))\n",
    "for i, brain in enumerate(X[:4]): \n",
    "    single_mouse_all_mris[i] = BU.flatten(new_coarsen(brain, coarsening_factor, mri_dims))\n",
    "\n",
    "BV.plot_interactive_panels(single_mouse_all_mris, coarsened_brain.shape, coarsened_nl_mask, figsize=(17, 5), dir_labels=dir_labels, column_titles=[\"Coarsened Baseline\", \"Coarsened Pre-fear\", \"Coarsened Fear\", \"Coarsened D9\"])\n"
   ]
  },
  {
   "source": [
    "My thoughts on the coarsened brains: \n",
    "- It's certainly easier to click through all the slices in the coarsened version \n",
    "- I think that coarsening by a factor of 5 reduces the resolution so much that the images become less useful to look at \n",
    "- Coarsening by a factor of 3 reduces the dimensionality of the data (though it is still very high dimensional data), but the images look much better \n",
    "- At our current analysis stage, the coarsening process itself is by far the most time consuming process we do, so in that respect the coarsening is not too useful (yet)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " ## Correlation between each voxel of brains and Y (percent time spent in the light)\n",
    "\n",
    "\n",
    "For each voxel (after coarsening): \n",
    "- have 20 pairs of values: MRI (fear - pre-fear)  and Y (fear- pre-fear)\n",
    "- want to find correlation for ^ for each voxel \n",
    "- graph back onto the brain "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 79\n",
    "\n",
    "# new array of coarsened brain images \n",
    "X_new = np.zeros((n_images, np.prod(coarsened_brain.shape)))\n",
    "for i in range(n_images): \n",
    "    X_new[i] = BU.flatten(new_coarsen(X[i], coarsening_factor, np.array(mri_dims)))\n",
    "\n",
    "np.save(os.path.join('coarsened3_X.npy'), X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(79, 78792)"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "X_new = np.load(os.path.join('coarsened3_X.npy'))\n",
    "\n",
    "Y_diffs = Y.PerLight[timepoints_dir[\"Fear\"]].to_numpy() - Y.PerLight[timepoints_dir[\"PreF\"]].to_numpy()\n",
    "\n",
    "X_diffs = X_new[timepoints_dir[\"Fear\"]] - X_new[timepoints_dir[\"PreF\"]]\n",
    "\n",
    "corrs = np.zeros( X_new.shape[1], dtype=np.int16)\n",
    "\n",
    "\n",
    "\n",
    "for voxel in range(X_new.shape[1]): \n",
    "    value = pearsonr(Y_diffs, X_diffs[:, voxel])[0]\n",
    "    if np.isnan(value): \n",
    "        value = 0 \n",
    "    corrs[voxel] = value\n",
    "\n",
    "#note: when everything is a 0, pearsonr returns a nan correlation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\"correlations.npy\"), corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=24), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c12d2894b4849aba7fdf8f27053824b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=39), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69c020ec7181483cade80c054be78529"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=0, continuous_update=False, description='brain_slice', max=16), Output()…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8533a48878334eb491c10c70758e2184"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "BV.plot_interactive_panels(corrs, coarsened_brain.shape, coarsened_nl_mask, figsize=(12, 5), dir_labels=dir_labels, std_scale='corr', column_titles=[\"Correlations for Coarsened Brain\"], step=1)"
   ]
  },
  {
   "source": [
    "My take on the above graph: \n",
    "It's hard to tell if there's anything there. Note that the scale only varies between +- 0.6 (no extremely strong correlations )"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "########## Extra stuff \n",
    "\n",
    "\n",
    "\n",
    "## Mean and Variance side-by-side\n",
    "\n",
    "# display heatmaps \n",
    "# BV.plot_interactive_panels(np.vstack((HM_list[0], var_dir['BL'], HM_list[1], var_dir['PreF'])), mri_dims, nolin_mask_vec, figsize=(17, 3), dir_labels=dir_labels, column_titles=[\"BL Mean\", \"BL variance\", \"Pre-fear Mean\", \"Pre-fear Var\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Heatmap of the WT vs KO mice\n",
    "\n",
    "\n",
    "# WT_indices = Y[Y[\"Genotype\"]==\"WT\"].index.tolist()\n",
    "# KO_indices = Y.dropna(how='any', axis=0)[Y[\"Genotype\"]==\"KO\"].index.tolist() #remove last value bc it doesn't have an associated MRI \n",
    "\n",
    "# # create wild type heatmap \n",
    "# heatmap_WT = np.zeros(np.prod(mri_dims))\n",
    "# n = X[WT_indices].shape[0]\n",
    "# for brain in tqdm(X[WT_indices]):\n",
    "#     heatmap_WT += brain\n",
    "# np.divide(heatmap_WT, n)\n",
    "# np.save(os.path.join('heatmap_WT.npy'), heatmap)\n",
    "\n",
    "\n",
    "# # create KO heatmap \n",
    "# heatmap_KO = np.zeros(np.prod(mri_dims))\n",
    "# n = X[KO_indices].shape[0]\n",
    "# for brain in tqdm(X[KO_indices]):\n",
    "#     heatmap_KO += brain\n",
    "# np.divide(heatmap_KO, n) \n",
    "# np.save(os.path.join('heatmap_KO.npy'), heatmap)\n",
    "\n",
    "\n",
    "# heatmap_WT = np.load(os.path.join('heatmap_WT.npy'))\n",
    "# heatmap_KO = np.load(os.path.join('heatmap_KO.npy'))\n",
    "\n",
    "# BV.plot_interactive_panels(np.vstack((heatmap_WT, heatmap_KO)), mri_dims, nolin_mask_vec, figsize=(10, 5), dir_labels=dir_labels, column_titles=[\"Wild-type\", \"Knockout\"], step=1)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save correlations as nii image \n",
    "corrs = np.load('correlations.npy')\n",
    "\n",
    "corrs = BU.unflatten(corrs, (42, 67, 28))\n",
    "nii_corrs = nib.Nifti1Image(corrs, nib_loaded_img.affine)\n",
    "\n",
    "nib.save(nii_corrs, os.path.join('PTSDMice_coarsenedCorrelations.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<nibabel.nifti1.Nifti1Image at 0x2139b2be1c8>"
      ]
     },
     "metadata": {},
     "execution_count": 190
    }
   ],
   "source": [
    "img = nib.load('PTSDMice_coarsenedCorrelations.nii')\n",
    "img.aff2ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}