{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd07f74fb8d6499ee4bda8fc6644f91bbeb50318e949a35bfb3f74522bd79400fb6",
   "display_name": "Python 3.8.5 64-bit ('cfl-env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Dimensions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "\n",
    "import sys \n",
    "sys.path.append('/Users/jkahn/Documents/Schmidt/cfl')\n",
    "from cfl.util.brain_util import load_brain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single run for a single subject \n",
    "mris = np.load('100206_rfMRI_REST1_LR.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(91282, 1200)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# this mri has shape (90K voxels, 1200 timepoints)\n",
    "mris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parcels \n",
    "parcels = np.load('parcels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(91282,)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# same dimensions as a single timeframe of MRI \n",
    "parcels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "        55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "        66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "        77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "        88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "        99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "       110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "       121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
       "       132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142.,\n",
       "       143., 144., 145., 146., 147., 148., 149., 150., 151., 152., 153.,\n",
       "       154., 155., 156., 157., 158., 159., 160., 161., 162., 163., 164.,\n",
       "       165., 166., 167., 168., 169., 170., 171., 172., 173., 174., 175.,\n",
       "       176., 177., 178., 179., 180., 181., 182., 183., 184., 185., 186.,\n",
       "       187., 188., 189., 190., 191., 192., 193., 194., 195., 196., 197.,\n",
       "       198., 199., 200., 201., 202., 203., 204., 205., 206., 207., 208.,\n",
       "       209., 210., 211., 212., 213., 214., 215., 216., 217., 218., 219.,\n",
       "       220., 221., 222., 223., 224., 225., 226., 227., 228., 229., 230.,\n",
       "       231., 232., 233., 234., 235., 236., 237., 238., 239., 240., 241.,\n",
       "       242., 243., 244., 245., 246., 247., 248., 249., 250., 251., 252.,\n",
       "       253., 254., 255., 256., 257., 258., 259., 260., 261., 262., 263.,\n",
       "       264., 265., 266., 267., 268., 269., 270., 271., 272., 273., 274.,\n",
       "       275., 276., 277., 278., 279., 280., 281., 282., 283., 284., 285.,\n",
       "       286., 287., 288., 289., 290., 291., 292., 293., 294., 295., 296.,\n",
       "       297., 298., 299., 300., 301., 302., 303., 304., 305., 306., 307.,\n",
       "       308., 309., 310., 311., 312., 313., 314., 315., 316., 317., 318.,\n",
       "       319., 320., 321., 322., 323., 324., 325., 326., 327., 328., 329.,\n",
       "       330., 331., 332., 333., 334., 335., 336., 337., 338., 339., 340.,\n",
       "       341., 342., 343., 344., 345., 346., 347., 348., 349., 350., 351.,\n",
       "       352., 353., 354., 355., 356., 357., 358., 359., 360., 361., 362.,\n",
       "       363., 364., 365., 366., 367., 368., 369., 370., 371., 372., 373.,\n",
       "       374., 375., 376., 377., 378., 379., 380., 381., 382., 383., 384.,\n",
       "       385., 386., 387., 388., 389., 390., 391., 392., 393., 394., 395.,\n",
       "       396., 397., 398., 399., 400., 401., 402., 403., 404., 405.])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# parcels are aligned with MRIs \n",
    "np.unique(parcels)"
   ]
  },
  {
   "source": [
    "## Get the data into a good shape for visualizing \n",
    "\n",
    "From Julien:  \n",
    "\n",
    "\"\n",
    "So I think the best way to get the data in the .npy files back into a volume format that you can visualize is the following:\n",
    "\n",
    "1. read the .npy, save to a .tsv file (voxels x time)\n",
    "\n",
    "2. use the command line connectome workbench (wb_command) to write the data to a .dtseries.nii file. You'll need a template, attached to this email\n",
    "\n",
    "3. then you should be able to visualize the data in the connectome workbench viewer (wb_view). You'll want to load up a structural MRI too, I think there is all you need in the Box folder.\n",
    "\n",
    "With wb_command you will be able to parcellate the data using the Parcels.dlabel.nii file, and produce a .ptseries.nii (parcellated time series) from the .dtseries.nii (dense time series).\n",
    "You can also just load up the parcellation in connectome workbench, I think I have instructions in that same box folder.\n",
    "\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100206_rfMRI_REST1_LR\n"
     ]
    }
   ],
   "source": [
    "file_path = '100206_rfMRI_REST1_LR.npy'\n",
    "\n",
    "file_name = file_path.split(sep='.')[0]\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single run for a single subject \n",
    "mris = np.load(file_path)\n",
    "\n",
    "    # # save the run as a .tsv file \n",
    "    # np.savetxt(file_name + '.tsv', mris, delimiter='\\t')"
   ]
  },
  {
   "source": [
    "Now open terminal, `cd` into the folder where the MRI is \n",
    "\n",
    "The command to do is \n",
    "```\n",
    "wb_command -cifti-convert -from-text <text-in> <cifti-template> <text-out>\n",
    "```\n",
    "\n",
    "Help for wb_command -cifti-convert: \n",
    "[-from-text] - convert from plain text to cifti\n",
    "         <text-in> - the input text file\n",
    "         <cifti-template> - a cifti file with the dimension(s) and mapping(s)\n",
    "            that should be used\n",
    "         <cifti-out> - output - the output cifti file\n",
    "\n",
    "\n",
    "The exact command to do is: \n",
    "```\n",
    "wb_command -cifti-convert -from-text 100206_rfMRI_REST1_LR.tsv example.dtseries.nii test.dtseries.nii\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_timepoint = mris[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the run as a .tsv file \n",
    "np.savetxt('test.tsv', one_timepoint, delimiter='\\t')"
   ]
  }
 ]
}